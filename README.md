# Word2vec
This project implements the Word2Vec algorithm, a popular technique in natural language processing (NLP) for generating word embeddings. Word2Vec is a neural network-based algorithm that learns distributed representations of words from text data. Word2Vec represents words as vectors to learn word associations.

## Model Architecture

The Word2Vec project aims to train word embeddings using the continuous bag-of-words (CBOW) model. These embeddings can be used for a variety of natural language processing (NLP) tasks, such as text classification, sentiment analysis and machine translation.

## Results

### Loss
![](https://github.com/Rutvik1727/Word2Vec/blob/main/Images/plt%20(3).png)

### Accuracy
![](https://github.com/Rutvik1727/Word2Vec/blob/main/Images/plt%20(2).png)

### Word Embedding Visualization
![](https://github.com/Rutvik1727/Word2Vec/blob/main/Images/plt%20(1).png)
